{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07b1b6f1-7c38-443d-b944-011b2f2f2082",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "with open(\"final_list_yerke_vector_db_final.pkl\", \"rb\") as f:\n",
    "    mylist = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "601b0a2b-c680-4d93-94e3-61b0dc911224",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastembed import TextEmbedding\n",
    "from qdrant_client import QdrantClient\n",
    "\n",
    "Qclient = QdrantClient(url=\"http://localhost:6333\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1cd7e777-e70e-49d5-9526-4e3e24b12104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qdrant_client.models import Distance, VectorParams\n",
    "\n",
    "\n",
    "collection_name = \"YerkeChatBot\"\n",
    "\n",
    "\n",
    "\n",
    "if Qclient.collection_exists(collection_name=f\"{collection_name}\"):\n",
    "    Qclient.delete_collection(collection_name=f\"{collection_name}\")\n",
    "Qclient.create_collection(\n",
    "    collection_name=f\"{collection_name}\",\n",
    "    vectors_config=VectorParams(size=768, distance=Distance.COSINE),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f24b8806-861f-415e-ad13-147d65d19b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Qclient.collection_exists(collection_name=f\"{collection_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8662659a-aaf5-4de8-a0e4-7e492289212c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 28416.69it/s]\n"
     ]
    }
   ],
   "source": [
    "model = TextEmbedding(\"nomic-ai/nomic-embed-text-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56de58d6-6ab5-4a58-ac2f-bce9f5db6d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 695/695 [00:35<00:00, 19.33it/s]\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client.models import PointStruct\n",
    "import numpy as np \n",
    "from tqdm import tqdm \n",
    "mypoints = [] \n",
    "mypoints_save = []\n",
    "for idx, eachList in enumerate(tqdm(mylist)):\n",
    "    title = eachList['title']\n",
    "    summary = eachList['summary']\n",
    "    context = eachList[\"propositions\"]\n",
    "    embedding1 = next(model.embed([title]))\n",
    "    embedding2 = next(model.embed([summary]))\n",
    "    myvector = np.add(embedding1, embedding2)\n",
    "    item = PointStruct(id=idx, vector = myvector.tolist(), payload={\n",
    "        \"summary\": summary,\n",
    "        \"context\": context})\n",
    "    item_save = {\"id\": idx, \"vector\":  myvector.tolist(), \n",
    "                 \"payload\": {\"summary\": summary, \"context\": context}\n",
    "                }\n",
    "    mypoints.append(item)\n",
    "    mypoints_save.append(item_save)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cc89f7f4-c876-452c-9d75-cb6b96eac401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "operation_id=0 status=<UpdateStatus.COMPLETED: 'completed'>\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client.models import PointStruct\n",
    "\n",
    "operation_info = Qclient.upsert(\n",
    "    collection_name=f\"{collection_name}\",\n",
    "    wait=True,\n",
    "    points=mypoints\n",
    ")\n",
    "\n",
    "print(operation_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9b011eaf-166b-45a7-9d11-83c747b5f93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"When will the Zoom broadcast be?\"\n",
    "query_vector = next(model.embed(query))\n",
    "\n",
    "search_result = Qclient.search(\n",
    "    collection_name=f\"{collection_name}\",\n",
    "    query_vector=query_vector.tolist(), limit=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f0daa747-3da4-4bc6-b71b-b87555685a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ScoredPoint(id=685, version=0, score=0.7818057, payload={'context': ['Zoom will be broadcast on Mondays from 20:00 to 21:00.', 'A second Zoom broadcast takes place on Thursdays between 21:00 and 22:00.', 'The Thursday Zoom broadcast is different every week.', 'The Thursday Zoom broadcast accommodates people with different schedules.', 'Participants will receive additional information on the Thursday Zoom broadcast.', 'The additional information about the Thursday Zoom broadcast does not affect the main lessons or homework.'], 'summary': 'This chunk contains information about the recurring Zoom broadcasts, including their schedule, weekly variations, and additional information for participants.'}, vector=None, shard_key=None, order_value=None)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e5ab125-70ee-4720-8a9e-7bfb2aaa0365",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \" \".join(search_result[0].payload[\"context\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3a729b30-59e4-4357-95a4-eab463086378",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = search_result[0].score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "955177f2-d807-478a-8298-f2ad89503d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7818057"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7dc31d7e-7f66-40ae-a66f-2e6453b45008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Zoom will be broadcast on Mondays from 20:00 to 21:00. A second Zoom broadcast takes place on Thursdays between 21:00 and 22:00. The Thursday Zoom broadcast is different every week. The Thursday Zoom broadcast accommodates people with different schedules. Participants will receive additional information on the Thursday Zoom broadcast. The additional information about the Thursday Zoom broadcast does not affect the main lessons or homework.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "46a1914e-1c4a-4fae-8b94-8ca9bedcb9ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openai'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[1;32m      3\u001b[0m client \u001b[38;5;241m=\u001b[39m OpenAI(\n\u001b[1;32m      4\u001b[0m     base_url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp://localhost:11434/v1/\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m     api_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mollama\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m )\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'openai'"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1/',\n",
    "    api_key='ollama',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2c63a499-41ff-4899-8f97-ca6714d6c264",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = f\"\"\"\n",
    "    Answer the \"QUESTION\" in detail, based on the \"CONTEXT\" provided. If context is empty, give answer as a financial advisor.\n",
    "    QUESTION: \n",
    "    {query}\n",
    "    CONTEXT: \n",
    "    {context}\n",
    "    \"\"\".strip()\n",
    "context = \"\\n\".join(search_result[0].payload[\"context\"]) if search_result[0].score >= 0.5 else \"\"\n",
    "prompt = prompt_template.format(query=query, context=context).strip()\n",
    "\n",
    "def llm(prompt):\n",
    "    prompt_template = f\"\"\"\n",
    "    Answer the \"QUESTION\" in detail, based on the \"CONTEXT\" provided. If context is empty, give answer as a financial advisor.\n",
    "    QUESTION: \n",
    "    {query}\n",
    "    CONTEXT: \n",
    "    {context}\n",
    "    \"\"\".strip()\n",
    "    context = \"\\n\".join(search_result[0].payload[\"context\"])\n",
    "    prompt = prompt_template.format(query=query, context=context).strip()\n",
    "    response = client.chat.completions.create(\n",
    "        model='gemma2',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14683d8b-92c5-4c6a-aa14-8fafee50d0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35a6eed-4f1a-4763-b304-18fabb34c495",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "alls = []\n",
    "for i in range(10):\n",
    "    start_time = time.perf_counter()\n",
    "    llm(prompt)\n",
    "    end_time = time.perf_counter()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Elapsed time: {elapsed_time :.6f} seconds\")\n",
    "    alls.append(elapsed_time)\n",
    "    \n",
    "print( \"Average: \", sum(alls) / 10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab951377-3350-42b2-bdeb-82929fadb650",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list | grep sentence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
